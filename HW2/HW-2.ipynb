{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2abc7a41",
   "metadata": {},
   "source": [
    "# Homework 2: Discover, Measure, and Mitigate Bias in Bank Marketing\n",
    "\n",
    "## Background\n",
    "\n",
    "In this homework, we use a data coming from a bank’s marketing campaign. It consists of several individual level variables like age, gender, credit default, job etc., which can serve as input variables in the prediction model. The outcome varaible that the bank is interested in is whether a person subscribed to the term deposit or not. Hence, the outcome variable is categorical in nature ‐ subscribed or did not subscribe. The objective of training a model is to predict if someone would subscribe to the term deposit oﬀered by the bank or not. Given that the cost and time to contact all possible leads is enormous hence, ﬁnancial institutions like to identify the most promising leads. Promising leads are likely to be identiﬁed as proﬁle of people who are most likely to subscribe to a term deposit. Once identiﬁed, these leads are contacted through direct marketing channels (e.g., phone calls), they are provided with all the details about the term deposit.\n",
    "\n",
    "But the bank also wants to make sure that the prediction model is not biased against any group. They are cognizant that a prediction model built on prior data set has the potential to display bias against diﬀerent groups which precludes them from appearing in the list of promising leads. Considering that term deposits can help secure ﬁnancial stability in the long term, a biased prediction model can adversely aﬀect some groups. For the purpose of this project, we will consider marital status (married, not married) as the protected variable of interest. We will refer to the married people as the privileged group and examine whether there is diﬀerences in the privileged group versus the unprivileged group.\n",
    "\n",
    "| Protected Variable|Privileged Group|Unprivileged Group|\n",
    "| ----------------- | -------------- | ---------------- |\n",
    "| Marital status\t| Married        |Unmarried         |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d005adf",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "The dataset consists of $5000$ rows and $12$ kinds of features. Run the code below to show a subset of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7c87811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>subscribed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>45</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>42</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>53</td>\n",
       "      <td>admin.</td>\n",
       "      <td>divorced</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>37</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>44</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age          job   marital            education  default housing loan  \\\n",
       "0    56    housemaid   married             basic.4y       no      no   no   \n",
       "1    57     services   married          high.school  unknown      no   no   \n",
       "2    37     services   married          high.school       no     yes   no   \n",
       "3    40       admin.   married             basic.6y       no      no   no   \n",
       "4    56     services   married          high.school       no      no  yes   \n",
       "..  ...          ...       ...                  ...      ...     ...  ...   \n",
       "95   45     services   married  professional.course       no     yes   no   \n",
       "96   42   management   married    university.degree       no      no   no   \n",
       "97   53       admin.  divorced    university.degree  unknown      no   no   \n",
       "98   37   technician    single  professional.course       no      no   no   \n",
       "99   44  blue-collar   married             basic.6y       no      no   no   \n",
       "\n",
       "      contact month day_of_week  ...  campaign  pdays  previous     poutcome  \\\n",
       "0   telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "1   telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "2   telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "3   telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "4   telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "..        ...   ...         ...  ...       ...    ...       ...          ...   \n",
       "95  telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "96  telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "97  telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "98  telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "99  telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "\n",
       "   emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed  \\\n",
       "0           1.1          93.994          -36.4      4.857       5191.0   \n",
       "1           1.1          93.994          -36.4      4.857       5191.0   \n",
       "2           1.1          93.994          -36.4      4.857       5191.0   \n",
       "3           1.1          93.994          -36.4      4.857       5191.0   \n",
       "4           1.1          93.994          -36.4      4.857       5191.0   \n",
       "..          ...             ...            ...        ...          ...   \n",
       "95          1.1          93.994          -36.4      4.857       5191.0   \n",
       "96          1.1          93.994          -36.4      4.857       5191.0   \n",
       "97          1.1          93.994          -36.4      4.857       5191.0   \n",
       "98          1.1          93.994          -36.4      4.857       5191.0   \n",
       "99          1.1          93.994          -36.4      4.857       5191.0   \n",
       "\n",
       "    subscribed  \n",
       "0           no  \n",
       "1           no  \n",
       "2           no  \n",
       "3           no  \n",
       "4           no  \n",
       "..         ...  \n",
       "95          no  \n",
       "96          no  \n",
       "97          no  \n",
       "98          no  \n",
       "99          no  \n",
       "\n",
       "[100 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "bank_data = pd.read_csv('bank.csv', delimiter=';')\n",
    "bank_data.head(n=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba5ca5b",
   "metadata": {},
   "source": [
    "The table is referred to as the Original data because this is the data before any analysis has been performed on it.  The outcome variable of $subscribed$ denotes if the client has subscribed to a term deposit. For ease of explanation, we will refer to the two classes of the outcome variable as yes versus no indicating whether a person subscribed (yes) or did not subscribe (no). All features are:\n",
    "\n",
    "* $age$: How old this client is. \n",
    "* $job$: Type of job. \n",
    "* $marital$: Marital status.\n",
    "* $education$: Highest education.\n",
    "* $default$: Has credit in default.\n",
    "* $housing$: Has housing loan?\n",
    "* $loan$: Has personal loan? \n",
    "* $contact$: Contact communication type.\n",
    "* $month$: Last contact month of year.\n",
    "* $day\\_of\\_week$: Last contact day of the week.\n",
    "* $duration$: Last contact duration, in seconds.\n",
    "* $subscribed$: Has the client subscribed a term deposit？ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9f7f72",
   "metadata": {},
   "source": [
    "## Steps to Discover, Measure, and Mitigate Bias\n",
    "\n",
    "![image](../Images/MLWorkflow.png)\n",
    "\n",
    "* Import statements\n",
    "* Specify protected variable, privileged group, and unprivileged group\n",
    "* Split the Bank Marketing data into training data and test data.\n",
    "* Build a prediction model without debiasing techniques. (Baseline)\n",
    "    * Train a Logistic Regression model using the training data.\n",
    "    * Make prediction of the test data with the trained model.\n",
    "    * Check fairness metrics and accuracy of the predition.\n",
    "* Apply debiasing techniques to mitigate biases in prediction.\n",
    "    * Pre-processing techniques\n",
    "    * In-processing techniques\n",
    "    * Post-processing techniques\n",
    "* flexibly combine different debiasing techniques to mitigate biases in prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7ca2ab",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19df39b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.datasets import BankDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from aif360.algorithms.preprocessing import LFR\n",
    "from aif360.algorithms.inprocessing import PrejudiceRemover\n",
    "from aif360.algorithms.postprocessing import RejectOptionClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ef5eb6",
   "metadata": {},
   "source": [
    "### Load the bank data, Specify protected variable, privileged group, and unprivileged group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0fdccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "protected_attribute_maps = [{1.0: 'married', 0.0: 'unmarried'}]\n",
    "dataset_orig = BankDataset(\n",
    "            protected_attribute_names=['marital'],          \n",
    "            privileged_classes=[['married']], \n",
    "            features_to_drop=['campaign', 'pdays', 'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'],\n",
    "            categorical_features=['job', 'education', 'default',\n",
    "                    'housing', 'loan', 'contact', 'month', 'day_of_week'],\n",
    "            metadata={'protected_attribute_maps': protected_attribute_maps}\n",
    "        )\n",
    "privileged_groups = [{'marital': 1}]\n",
    "unprivileged_groups = [{'marital': 0}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d928df05",
   "metadata": {},
   "source": [
    "### Split the dataset into training data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b7ee0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97b41bd",
   "metadata": {},
   "source": [
    "### Check fairness metrics of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4af18746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPD 0.18\n",
      "DI 1.7\n"
     ]
    }
   ],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                     unprivileged_groups=unprivileged_groups,\n",
    "                                     privileged_groups=privileged_groups)\n",
    "# print the metric values \n",
    "print('SPD', round(metric_orig_train.mean_difference(), 2))\n",
    "print('DI', round(metric_orig_train.disparate_impact(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4968c6",
   "metadata": {},
   "source": [
    "### Build a model without mitigation methods. (Baseline)\n",
    "\n",
    "#### Train a Logistic Regression model using the training data. Make predictions on the test data using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e427060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the dataset with Logistic Regression model\n",
    "def Logistic_Regression(training_data, test_data):\n",
    "    model = LogisticRegression(random_state=0, max_iter = 1000)\n",
    "    # train model\n",
    "    model.fit(training_data.features, training_data.labels.ravel())\n",
    "    # test the model\n",
    "    prediction_label = model.predict(test_data.features)\n",
    "    prediction = dataset_orig_test.copy()\n",
    "    prediction.labels = prediction_label\n",
    "    # return the prediction on the test data\n",
    "    return prediction\n",
    "\n",
    "prediction = Logistic_Regression(dataset_orig_train, dataset_orig_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7652e3",
   "metadata": {},
   "source": [
    "#### Check fairness metrics and accuracy of the predition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8def1e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7973333333333333\n",
      "0.16\n",
      "1.7\n",
      "0.08\n",
      "0.05\n"
     ]
    }
   ],
   "source": [
    "# measure the accuracy and the fairness metrics on the prediction\n",
    "def get_prediction_metrics(prediction):\n",
    "    metric = ClassificationMetric(\n",
    "                        dataset_orig_test, prediction,\n",
    "                        unprivileged_groups=unprivileged_groups,\n",
    "                        privileged_groups=privileged_groups)\n",
    "\n",
    "    accuracy = metric.accuracy()\n",
    "    print('accuracy', accuracy)\n",
    "    print(round(metric.statistical_parity_difference(), 2))\n",
    "    print(round(metric.disparate_impact(), 2))\n",
    "    print(round(metric.equal_opportunity_difference(), 2))\n",
    "    print(round(metric.average_odds_difference(), 2))\n",
    "\n",
    "get_prediction_metrics(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167b17b3",
   "metadata": {},
   "source": [
    "### Apply different mitigation methods to get debiased prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65bd4ee",
   "metadata": {},
   "source": [
    "#### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e75111e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPD 0.0\n",
      "DI 1.0\n"
     ]
    }
   ],
   "source": [
    "# Pre-processing: reweighing method\n",
    "RW_model = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "            privileged_groups=privileged_groups)\n",
    "dataset_RW_train = RW_model.fit_transform(dataset_orig_train)\n",
    "metric_RW_train = BinaryLabelDatasetMetric(dataset_RW_train, \n",
    "                                     unprivileged_groups=unprivileged_groups,\n",
    "                                     privileged_groups=privileged_groups)\n",
    "\n",
    "# print the metric values \n",
    "print('SPD', round(metric_RW_train.mean_difference(), 2))\n",
    "print('DI', round(metric_RW_train.disparate_impact(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa329a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPD 0.0\n",
      "DI 1.0\n"
     ]
    }
   ],
   "source": [
    "# Pre-processing: Learning fair representations\n",
    "LFR_model = LFR(unprivileged_groups=unprivileged_groups, \n",
    "    privileged_groups=privileged_groups,\n",
    "    verbose=0, seed=10)\n",
    "LFR_model = LFR_model.fit(dataset_orig_train)\n",
    "dataset_LFR_train = LFR_model.transform(dataset_orig_train)\n",
    "\n",
    "metric_LFR_train = BinaryLabelDatasetMetric(dataset_LFR_train, \n",
    "                                        unprivileged_groups=unprivileged_groups,\n",
    "                                        privileged_groups=privileged_groups)\n",
    "print('SPD', round(metric_RW_train.mean_difference(), 2))\n",
    "print('DI', round(metric_RW_train.disparate_impact(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a56e4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7013333333333334\n",
      "0.0\n",
      "1.01\n",
      "-0.11\n",
      "-0.09\n",
      "accuracy 0.7973333333333333\n",
      "0.16\n",
      "1.7\n",
      "0.08\n",
      "0.05\n"
     ]
    }
   ],
   "source": [
    "# training the original model with the processed training data\n",
    "prediction = Logistic_Regression(dataset_LFR_train, dataset_orig_test)\n",
    "get_prediction_metrics(prediction)\n",
    "\n",
    "prediction = Logistic_Regression(dataset_RW_train, dataset_orig_test)\n",
    "get_prediction_metrics(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b9068c",
   "metadata": {},
   "source": [
    "#### In-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c055a7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.798\n",
      "0.17\n",
      "1.84\n",
      "0.13\n",
      "0.08\n"
     ]
    }
   ],
   "source": [
    "# in-processing: Prejudice remover\n",
    "model = PrejudiceRemover(eta=0.1)\n",
    "model.fit(dataset_orig_train)\n",
    "prediction = model.predict(dataset_orig_test)\n",
    "get_prediction_metrics(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a643673b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/yanxinyuan/opt/anaconda3/envs/HWfairAIVenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-20 17:14:33.261624: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-20 17:14:33.802681: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 7.859415; batch adversarial loss: 0.769911\n",
      "epoch 1; iter: 0; batch classifier loss: 3.744248; batch adversarial loss: 0.769484\n",
      "epoch 2; iter: 0; batch classifier loss: 2.387394; batch adversarial loss: 0.729065\n",
      "epoch 3; iter: 0; batch classifier loss: 5.968015; batch adversarial loss: 0.746093\n",
      "epoch 4; iter: 0; batch classifier loss: 2.796527; batch adversarial loss: 0.724543\n",
      "epoch 5; iter: 0; batch classifier loss: 1.637925; batch adversarial loss: 0.700866\n",
      "epoch 6; iter: 0; batch classifier loss: 1.673924; batch adversarial loss: 0.711516\n",
      "epoch 7; iter: 0; batch classifier loss: 1.789078; batch adversarial loss: 0.711088\n",
      "epoch 8; iter: 0; batch classifier loss: 0.960733; batch adversarial loss: 0.715673\n",
      "epoch 9; iter: 0; batch classifier loss: 0.887707; batch adversarial loss: 0.710739\n",
      "epoch 10; iter: 0; batch classifier loss: 0.733396; batch adversarial loss: 0.724761\n",
      "epoch 11; iter: 0; batch classifier loss: 0.860014; batch adversarial loss: 0.703032\n",
      "epoch 12; iter: 0; batch classifier loss: 0.944111; batch adversarial loss: 0.695440\n",
      "epoch 13; iter: 0; batch classifier loss: 0.782661; batch adversarial loss: 0.705981\n",
      "epoch 14; iter: 0; batch classifier loss: 0.831736; batch adversarial loss: 0.702575\n",
      "epoch 15; iter: 0; batch classifier loss: 0.524327; batch adversarial loss: 0.699272\n",
      "epoch 16; iter: 0; batch classifier loss: 0.551514; batch adversarial loss: 0.688328\n",
      "epoch 17; iter: 0; batch classifier loss: 0.555733; batch adversarial loss: 0.705452\n",
      "epoch 18; iter: 0; batch classifier loss: 0.518569; batch adversarial loss: 0.697403\n",
      "epoch 19; iter: 0; batch classifier loss: 0.404655; batch adversarial loss: 0.702626\n",
      "epoch 20; iter: 0; batch classifier loss: 0.518237; batch adversarial loss: 0.687012\n",
      "epoch 21; iter: 0; batch classifier loss: 0.574243; batch adversarial loss: 0.683870\n",
      "epoch 22; iter: 0; batch classifier loss: 0.365219; batch adversarial loss: 0.695335\n",
      "epoch 23; iter: 0; batch classifier loss: 0.396741; batch adversarial loss: 0.679211\n",
      "epoch 24; iter: 0; batch classifier loss: 0.381803; batch adversarial loss: 0.691902\n",
      "epoch 25; iter: 0; batch classifier loss: 0.454132; batch adversarial loss: 0.687896\n",
      "epoch 26; iter: 0; batch classifier loss: 0.515567; batch adversarial loss: 0.690543\n",
      "epoch 27; iter: 0; batch classifier loss: 0.466233; batch adversarial loss: 0.692354\n",
      "epoch 28; iter: 0; batch classifier loss: 0.423047; batch adversarial loss: 0.690058\n",
      "epoch 29; iter: 0; batch classifier loss: 0.503418; batch adversarial loss: 0.688213\n",
      "epoch 30; iter: 0; batch classifier loss: 0.367088; batch adversarial loss: 0.682659\n",
      "epoch 31; iter: 0; batch classifier loss: 0.426640; batch adversarial loss: 0.679796\n",
      "epoch 32; iter: 0; batch classifier loss: 0.512401; batch adversarial loss: 0.693354\n",
      "epoch 33; iter: 0; batch classifier loss: 0.446467; batch adversarial loss: 0.679401\n",
      "epoch 34; iter: 0; batch classifier loss: 0.445061; batch adversarial loss: 0.675763\n",
      "epoch 35; iter: 0; batch classifier loss: 0.437639; batch adversarial loss: 0.687178\n",
      "epoch 36; iter: 0; batch classifier loss: 0.418414; batch adversarial loss: 0.700094\n",
      "epoch 37; iter: 0; batch classifier loss: 0.374018; batch adversarial loss: 0.678193\n",
      "epoch 38; iter: 0; batch classifier loss: 0.399991; batch adversarial loss: 0.673400\n",
      "epoch 39; iter: 0; batch classifier loss: 0.424215; batch adversarial loss: 0.682958\n",
      "epoch 40; iter: 0; batch classifier loss: 0.406664; batch adversarial loss: 0.690811\n",
      "epoch 41; iter: 0; batch classifier loss: 0.429599; batch adversarial loss: 0.699810\n",
      "epoch 42; iter: 0; batch classifier loss: 0.329048; batch adversarial loss: 0.678931\n",
      "epoch 43; iter: 0; batch classifier loss: 0.515136; batch adversarial loss: 0.668522\n",
      "epoch 44; iter: 0; batch classifier loss: 0.444762; batch adversarial loss: 0.689508\n",
      "epoch 45; iter: 0; batch classifier loss: 0.371288; batch adversarial loss: 0.684888\n",
      "epoch 46; iter: 0; batch classifier loss: 0.394906; batch adversarial loss: 0.684404\n",
      "epoch 47; iter: 0; batch classifier loss: 0.402492; batch adversarial loss: 0.675120\n",
      "epoch 48; iter: 0; batch classifier loss: 0.370919; batch adversarial loss: 0.692784\n",
      "epoch 49; iter: 0; batch classifier loss: 0.402549; batch adversarial loss: 0.650693\n",
      "accuracy 0.792\n",
      "0.11\n",
      "1.3\n",
      "-0.06\n",
      "-0.03\n"
     ]
    }
   ],
   "source": [
    "# in-processing: Adversarial debiasing\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "num_epochs = 50\n",
    "classifier_num_hidden_units = 200\n",
    "model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                            unprivileged_groups = unprivileged_groups,\n",
    "                            scope_name='debiased_classifier',\n",
    "                            debias=True,\n",
    "                            sess=sess)\n",
    "model.fit(dataset_RW_train)\n",
    "prediction = model.predict(dataset_orig_test)\n",
    "get_prediction_metrics(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd252ca",
   "metadata": {},
   "source": [
    "#### Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "036a2ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.756\n",
      "0.05\n",
      "1.27\n",
      "-0.05\n",
      "-0.04\n"
     ]
    }
   ],
   "source": [
    "model = RejectOptionClassification(privileged_groups = privileged_groups,\n",
    "                                unprivileged_groups = unprivileged_groups, num_class_thresh=500)\n",
    "model = model.fit(dataset_orig_test, prediction)\n",
    "prediction = model.predict(prediction)\n",
    "get_prediction_metrics(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42989f94",
   "metadata": {},
   "source": [
    "### Flexibly combine different techniques to generate debiased prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39173fd4",
   "metadata": {},
   "source": [
    "Give one example, let students try more examples with code\n",
    "Also try different split ratios"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HWfairAIVenv",
   "language": "python",
   "name": "hwfairaivenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
