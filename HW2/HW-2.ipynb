{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65a71aa5",
   "metadata": {},
   "source": [
    "# Homework 2: Discover, Measure, and Mitigate Bias in Bank Marketing\n",
    "\n",
    "## Background\n",
    "\n",
    "In this homework, we use a data coming from a bank’s marketing campaign. It consists of several individual level variables like age, gender, credit default, job etc., which can serve as input variables in the prediction model. The outcome varaible that the bank is interested in is whether a person subscribed to the term deposit or not. Hence, the outcome variable is categorical in nature ‐ subscribed or did not subscribe. The objective of training a model is to predict if someone would subscribe to the term deposit oﬀered by the bank or not. Given that the cost and time to contact all possible leads is enormous hence, ﬁnancial institutions like to identify the most promising leads. Promising leads are likely to be identiﬁed as proﬁle of people who are most likely to subscribe to a term deposit. Once identiﬁed, these leads are contacted through direct marketing channels (e.g., phone calls), they are provided with all the details about the term deposit.\n",
    "\n",
    "But the bank also wants to make sure that the prediction model is not biased against any group. They are cognizant that a prediction model built on prior data set has the potential to display bias against diﬀerent groups which precludes them from appearing in the list of promising leads. Considering that term deposits can help secure ﬁnancial stability in the long term, a biased prediction model can adversely aﬀect some groups. For the purpose of this project, we will consider marital status (married, not married) as the protected variable of interest. We will refer to the married people as the privileged group and examine whether there is diﬀerences in the privileged group versus the unprivileged group.\n",
    "\n",
    "| Protected Variable|Privileged Group|Unprivileged Group|\n",
    "| ----------------- | -------------- | ---------------- |\n",
    "| Marital status\t| Married        |Unmarried         |\n",
    "\n",
    "## Data Description\n",
    "The dataset consists of $5000$ rows and $12$ kinds of features. Run the code below to show a subset of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125a4e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bank_data = pd.read_csv('bank.csv', delimiter=';')\n",
    "bank_data.head(n=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61286331",
   "metadata": {},
   "source": [
    "The table is referred to as the Original data because this is the data before any analysis has been performed on it.  The outcome variable of $subscribed$ denotes if the client has subscribed to a term deposit. For ease of explanation, we will refer to the two classes of the outcome variable as yes versus no indicating whether a person subscribed (yes) or did not subscribe (no). All features are:\n",
    "\n",
    "* $age$: How old this client is. \n",
    "* $job$: Type of job. \n",
    "* $marital$: Marital status.\n",
    "* $education$: Highest education.\n",
    "* $default$: Has credit in default.\n",
    "* $housing$: Has housing loan?\n",
    "* $loan$: Has personal loan? \n",
    "* $contact$: Contact communication type.\n",
    "* $month$: Last contact month of year.\n",
    "* $day\\_of\\_week$: Last contact day of the week.\n",
    "* $duration$: Last contact duration, in seconds.\n",
    "* $subscribed$: Has the client subscribed a term deposit？ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e4eebd",
   "metadata": {},
   "source": [
    "## Steps to Discover, Measure, and Mitigate Bias\n",
    "\n",
    "![image](../Images/MLWorkflow.png)\n",
    "\n",
    "* Specify protected variable, privileged group, and unprivileged group\n",
    "* Split the data into training and test data.\n",
    "* Check fairness metrics of training data.\n",
    "* Build a model without mitigation methods. (Baseline)\n",
    "    * Train a Logistic Regression model using the training data.\n",
    "    * Make predictions on the test data using the trained model.\n",
    "    * Check fairness metrics and accuracy of the predition.\n",
    "* Apply different mitigation methods to get debiased prediction.\n",
    "    * **Pre-processing** 2\n",
    "    * **In-processing** 2\n",
    "    * **Post-processing** 1\n",
    "* Compare the debiased prediction with the baseline prediction w.r.t. accuracy and fairness metrics.\n",
    "* flexibly combine different techniques to generate debiased prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7ca2ab",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19df39b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.datasets import BankDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from aif360.algorithms.preprocessing import LFR\n",
    "from aif360.algorithms.inprocessing import PrejudiceRemover"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae05ff9",
   "metadata": {},
   "source": [
    "### Load the bank data, Specify protected variable, privileged group, and unprivileged group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fdccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "protected_attribute_maps = [{1.0: 'married', 0.0: 'unmarried'}]\n",
    "dataset_orig = BankDataset(\n",
    "            protected_attribute_names=['marital'],          \n",
    "            privileged_classes=[['married']], \n",
    "            features_to_drop=['campaign', 'pdays', 'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'],\n",
    "            categorical_features=['job', 'education', 'default',\n",
    "                    'housing', 'loan', 'contact', 'month', 'day_of_week'],\n",
    "            metadata={'protected_attribute_maps': protected_attribute_maps}\n",
    "        )\n",
    "privileged_groups = [{'marital': 1}]\n",
    "unprivileged_groups = [{'marital': 0}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d928df05",
   "metadata": {},
   "source": [
    "### Split the dataset into training data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b37417",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06858af2",
   "metadata": {},
   "source": [
    "### Check fairness metrics of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af18746",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                     unprivileged_groups=unprivileged_groups,\n",
    "                                     privileged_groups=privileged_groups)\n",
    "# print the metric values \n",
    "print('SPD', round(metric_orig_train.mean_difference(), 2))\n",
    "print('DI', round(metric_orig_train.disparate_impact(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1b2015",
   "metadata": {},
   "source": [
    "### Build a model without mitigation methods. (Baseline)\n",
    "\n",
    "#### Train a Logistic Regression model using the training data. Make predictions on the test data using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e427060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the dataset with Logistic Regression model\n",
    "def Logistic_Regression(training_data, test_data):\n",
    "    model = LogisticRegression(random_state=0, max_iter = 1000)\n",
    "    # train model\n",
    "    model.fit(training_data.features, training_data.labels.ravel())\n",
    "    # test the model\n",
    "    prediction_label = model.predict(test_data.features)\n",
    "    prediction = dataset_orig_test.copy()\n",
    "    prediction.labels = prediction_label\n",
    "    # return the prediction on the test data\n",
    "    return prediction\n",
    "\n",
    "prediction = Logistic_Regression(dataset_orig_train, dataset_orig_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4ec7f7",
   "metadata": {},
   "source": [
    "#### Check fairness metrics and accuracy of the predition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8def1e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure the accuracy and the fairness metrics on the prediction\n",
    "def get_prediction_metrics(prediction):\n",
    "    metric = ClassificationMetric(\n",
    "                        dataset_orig_test, prediction,\n",
    "                        unprivileged_groups=unprivileged_groups,\n",
    "                        privileged_groups=privileged_groups)\n",
    "\n",
    "    accuracy = metric.accuracy()\n",
    "    print('accuracy', accuracy)\n",
    "    print(round(metric.statistical_parity_difference(), 2))\n",
    "    print(round(metric.disparate_impact(), 2))\n",
    "    print(round(metric.equal_opportunity_difference(), 2))\n",
    "    print(round(metric.average_odds_difference(), 2))\n",
    "\n",
    "get_prediction_metrics(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96aa31e4",
   "metadata": {},
   "source": [
    "### Apply different mitigation methods to get debiased prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7852ec8c",
   "metadata": {},
   "source": [
    "#### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75111e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing: reweighing method\n",
    "RW_model = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "            privileged_groups=privileged_groups)\n",
    "dataset_RW_train = RW_model.fit_transform(dataset_orig_train)\n",
    "metric_RW_train = BinaryLabelDatasetMetric(dataset_RW_train, \n",
    "                                     unprivileged_groups=unprivileged_groups,\n",
    "                                     privileged_groups=privileged_groups)\n",
    "\n",
    "# print the metric values \n",
    "print('SPD', round(metric_RW_train.mean_difference(), 2))\n",
    "print('DI', round(metric_RW_train.disparate_impact(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa329a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing: Learning fair representations\n",
    "LFR_model = LFR(unprivileged_groups=unprivileged_groups, \n",
    "    privileged_groups=privileged_groups,\n",
    "    verbose=0, seed=10)\n",
    "LFR_model = LFR_model.fit(dataset_orig_train)\n",
    "dataset_LFR_train = LFR_model.transform(dataset_orig_train)\n",
    "\n",
    "metric_LFR_train = BinaryLabelDatasetMetric(dataset_LFR_train, \n",
    "                                        unprivileged_groups=unprivileged_groups,\n",
    "                                        privileged_groups=privileged_groups)\n",
    "print('SPD', round(metric_RW_train.mean_difference(), 2))\n",
    "print('DI', round(metric_RW_train.disparate_impact(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a56e4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the original model with the processed training data\n",
    "prediction = Logistic_Regression(dataset_LFR_train, dataset_orig_test)\n",
    "get_prediction_metrics(prediction)\n",
    "\n",
    "prediction = Logistic_Regression(dataset_RW_train, dataset_orig_test)\n",
    "get_prediction_metrics(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59032d16",
   "metadata": {},
   "source": [
    "#### In-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c055a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in-processing: Prejudice remover\n",
    "model = PrejudiceRemover(eta=0.1)\n",
    "model.fit(dataset_orig_train)\n",
    "prediction = model.predict(dataset_orig_test)\n",
    "get_prediction_metrics(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a643673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in-processing: Adversarial debiasing\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "num_epochs = 50\n",
    "classifier_num_hidden_units = 200\n",
    "model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                            unprivileged_groups = unprivileged_groups,\n",
    "                            scope_name='debiased_classifier',\n",
    "                            debias=True,\n",
    "                            sess=sess)\n",
    "model.fit(dataset_RW_train)\n",
    "prediction = model.predict(dataset_orig_test)\n",
    "get_prediction_metrics(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036a2ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:HWfairAIVenv]",
   "language": "python",
   "name": "conda-env-HWfairAIVenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
