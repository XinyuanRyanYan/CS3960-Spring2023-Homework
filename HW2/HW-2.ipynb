{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af7ca2ab",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19df39b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-20 15:06:30.061286: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from aif360.datasets import BankDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from aif360.algorithms.preprocessing import LFR\n",
    "from aif360.algorithms.inprocessing import PrejudiceRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0fdccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the bankdata\n",
    "protected_attribute_maps = [{1.0: 'married', 0.0: 'unmarried'}]\n",
    "dataset_orig = BankDataset(\n",
    "            protected_attribute_names=['marital'],          \n",
    "            privileged_classes=[['married']], \n",
    "            features_to_drop=['campaign', 'pdays', 'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'],\n",
    "            categorical_features=['job', 'education', 'default',\n",
    "                    'housing', 'loan', 'contact', 'month', 'day_of_week'],\n",
    "            metadata={'protected_attribute_maps': protected_attribute_maps}\n",
    "        )\n",
    "privileged_groups = [{'marital': 1}]\n",
    "unprivileged_groups = [{'marital': 0}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d928df05",
   "metadata": {},
   "source": [
    "* Split the dataset with ratio into training data and test data\n",
    "* Measure the fairness metrics of the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4af18746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPD 0.18\n",
      "DI 1.7\n"
     ]
    }
   ],
   "source": [
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=None)\n",
    "\n",
    "    \n",
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                     unprivileged_groups=unprivileged_groups,\n",
    "                                     privileged_groups=privileged_groups)\n",
    "\n",
    "# print the metric values \n",
    "print('SPD', round(metric_orig_train.mean_difference(), 2))\n",
    "print('DI', round(metric_orig_train.disparate_impact(), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e427060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the dataset with Logistic Regression model\n",
    "def Logistic_Regression(training_data, test_data):\n",
    "    model = LogisticRegression(random_state=0, max_iter = 1000)\n",
    "    # train model\n",
    "    model.fit(training_data.features, training_data.labels.ravel())\n",
    "    # test the model\n",
    "    prediction_label = model.predict(test_data.features)\n",
    "    prediction = dataset_orig_test.copy()\n",
    "    prediction.labels = prediction_label\n",
    "    # return the prediction on the test data\n",
    "    return prediction\n",
    "\n",
    "prediction = Logistic_Regression(dataset_orig_train, dataset_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8def1e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7973333333333333\n",
      "0.16\n",
      "1.7\n",
      "0.08\n",
      "0.05\n"
     ]
    }
   ],
   "source": [
    "# measure the accuracy and the fairness metrics on the prediction\n",
    "def get_prediction_metrics(prediction):\n",
    "    metric = ClassificationMetric(\n",
    "                        dataset_orig_test, prediction,\n",
    "                        unprivileged_groups=unprivileged_groups,\n",
    "                        privileged_groups=privileged_groups)\n",
    "\n",
    "    accuracy = metric.accuracy()\n",
    "    print('accuracy', accuracy)\n",
    "    print(round(metric.statistical_parity_difference(), 2))\n",
    "    print(round(metric.disparate_impact(), 2))\n",
    "    print(round(metric.equal_opportunity_difference(), 2))\n",
    "    print(round(metric.average_odds_difference(), 2))\n",
    "\n",
    "get_prediction_metrics(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e75111e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPD 0.0\n",
      "DI 1.0\n"
     ]
    }
   ],
   "source": [
    "# Pre-processing: reweighing method\n",
    "RW_model = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "            privileged_groups=privileged_groups)\n",
    "dataset_RW_train = RW_model.fit_transform(dataset_orig_train)\n",
    "metric_RW_train = BinaryLabelDatasetMetric(dataset_RW_train, \n",
    "                                     unprivileged_groups=unprivileged_groups,\n",
    "                                     privileged_groups=privileged_groups)\n",
    "\n",
    "# print the metric values \n",
    "print('SPD', round(metric_RW_train.mean_difference(), 2))\n",
    "print('DI', round(metric_RW_train.disparate_impact(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa329a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPD 0.0\n",
      "DI 1.0\n"
     ]
    }
   ],
   "source": [
    "# Pre-processing: Learning fair representations\n",
    "LFR_model = LFR(unprivileged_groups=unprivileged_groups, \n",
    "    privileged_groups=privileged_groups,\n",
    "    verbose=0, seed=10)\n",
    "LFR_model = LFR_model.fit(dataset_orig_train)\n",
    "dataset_LFR_train = LFR_model.transform(dataset_orig_train)\n",
    "\n",
    "metric_LFR_train = BinaryLabelDatasetMetric(dataset_LFR_train, \n",
    "                                        unprivileged_groups=unprivileged_groups,\n",
    "                                        privileged_groups=privileged_groups)\n",
    "print('SPD', round(metric_RW_train.mean_difference(), 2))\n",
    "print('DI', round(metric_RW_train.disparate_impact(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a56e4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7013333333333334\n",
      "0.0\n",
      "1.01\n",
      "-0.11\n",
      "-0.09\n",
      "accuracy 0.7973333333333333\n",
      "0.16\n",
      "1.7\n",
      "0.08\n",
      "0.05\n"
     ]
    }
   ],
   "source": [
    "# training the original model with the processed training data\n",
    "prediction = Logistic_Regression(dataset_LFR_train, dataset_orig_test)\n",
    "get_prediction_metrics(prediction)\n",
    "\n",
    "prediction = Logistic_Regression(dataset_RW_train, dataset_orig_test)\n",
    "get_prediction_metrics(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c055a7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.798\n",
      "0.17\n",
      "1.84\n",
      "0.13\n",
      "0.08\n"
     ]
    }
   ],
   "source": [
    "# in-processing: Prejudice remover\n",
    "model = PrejudiceRemover(eta=0.1)\n",
    "model.fit(dataset_orig_train)\n",
    "prediction = model.predict(dataset_orig_test)\n",
    "get_prediction_metrics(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a643673b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 7.415534; batch adversarial loss: 0.698311\n",
      "epoch 1; iter: 0; batch classifier loss: 4.718514; batch adversarial loss: 0.696130\n",
      "epoch 2; iter: 0; batch classifier loss: 3.182117; batch adversarial loss: 0.691449\n",
      "epoch 3; iter: 0; batch classifier loss: 3.366002; batch adversarial loss: 0.663497\n",
      "epoch 4; iter: 0; batch classifier loss: 3.189120; batch adversarial loss: 0.676688\n",
      "epoch 5; iter: 0; batch classifier loss: 2.056461; batch adversarial loss: 0.695969\n",
      "epoch 6; iter: 0; batch classifier loss: 1.870984; batch adversarial loss: 0.695920\n",
      "epoch 7; iter: 0; batch classifier loss: 1.150717; batch adversarial loss: 0.678812\n",
      "epoch 8; iter: 0; batch classifier loss: 1.191106; batch adversarial loss: 0.667851\n",
      "epoch 9; iter: 0; batch classifier loss: 1.233681; batch adversarial loss: 0.680741\n",
      "epoch 10; iter: 0; batch classifier loss: 0.692564; batch adversarial loss: 0.669964\n",
      "epoch 11; iter: 0; batch classifier loss: 0.601915; batch adversarial loss: 0.664089\n",
      "epoch 12; iter: 0; batch classifier loss: 0.651983; batch adversarial loss: 0.663189\n",
      "epoch 13; iter: 0; batch classifier loss: 0.613155; batch adversarial loss: 0.672363\n",
      "epoch 14; iter: 0; batch classifier loss: 0.798567; batch adversarial loss: 0.668587\n",
      "epoch 15; iter: 0; batch classifier loss: 0.535656; batch adversarial loss: 0.683907\n",
      "epoch 16; iter: 0; batch classifier loss: 0.434047; batch adversarial loss: 0.693348\n",
      "epoch 17; iter: 0; batch classifier loss: 0.430068; batch adversarial loss: 0.660319\n",
      "epoch 18; iter: 0; batch classifier loss: 0.537811; batch adversarial loss: 0.656900\n",
      "epoch 19; iter: 0; batch classifier loss: 0.465373; batch adversarial loss: 0.699387\n",
      "epoch 20; iter: 0; batch classifier loss: 0.594842; batch adversarial loss: 0.666255\n",
      "epoch 21; iter: 0; batch classifier loss: 0.585906; batch adversarial loss: 0.668257\n",
      "epoch 22; iter: 0; batch classifier loss: 0.442303; batch adversarial loss: 0.663007\n",
      "epoch 23; iter: 0; batch classifier loss: 0.476171; batch adversarial loss: 0.662558\n",
      "epoch 24; iter: 0; batch classifier loss: 0.412916; batch adversarial loss: 0.664242\n",
      "epoch 25; iter: 0; batch classifier loss: 0.452158; batch adversarial loss: 0.660096\n",
      "epoch 26; iter: 0; batch classifier loss: 0.456789; batch adversarial loss: 0.684636\n",
      "epoch 27; iter: 0; batch classifier loss: 0.390219; batch adversarial loss: 0.697397\n",
      "epoch 28; iter: 0; batch classifier loss: 0.412462; batch adversarial loss: 0.687390\n",
      "epoch 29; iter: 0; batch classifier loss: 0.445877; batch adversarial loss: 0.649290\n",
      "epoch 30; iter: 0; batch classifier loss: 0.373445; batch adversarial loss: 0.677340\n",
      "epoch 31; iter: 0; batch classifier loss: 0.469077; batch adversarial loss: 0.662370\n",
      "epoch 32; iter: 0; batch classifier loss: 0.370154; batch adversarial loss: 0.655287\n",
      "epoch 33; iter: 0; batch classifier loss: 0.439192; batch adversarial loss: 0.680722\n",
      "epoch 34; iter: 0; batch classifier loss: 0.457382; batch adversarial loss: 0.681093\n",
      "epoch 35; iter: 0; batch classifier loss: 0.472492; batch adversarial loss: 0.664459\n",
      "epoch 36; iter: 0; batch classifier loss: 0.448049; batch adversarial loss: 0.664366\n",
      "epoch 37; iter: 0; batch classifier loss: 0.418744; batch adversarial loss: 0.658375\n",
      "epoch 38; iter: 0; batch classifier loss: 0.372638; batch adversarial loss: 0.689847\n",
      "epoch 39; iter: 0; batch classifier loss: 0.377412; batch adversarial loss: 0.681651\n",
      "epoch 40; iter: 0; batch classifier loss: 0.429235; batch adversarial loss: 0.659080\n",
      "epoch 41; iter: 0; batch classifier loss: 0.378531; batch adversarial loss: 0.680783\n",
      "epoch 42; iter: 0; batch classifier loss: 0.399478; batch adversarial loss: 0.677742\n",
      "epoch 43; iter: 0; batch classifier loss: 0.386030; batch adversarial loss: 0.673057\n",
      "epoch 44; iter: 0; batch classifier loss: 0.372376; batch adversarial loss: 0.672661\n",
      "epoch 45; iter: 0; batch classifier loss: 0.360185; batch adversarial loss: 0.693602\n",
      "epoch 46; iter: 0; batch classifier loss: 0.334583; batch adversarial loss: 0.697429\n",
      "epoch 47; iter: 0; batch classifier loss: 0.473593; batch adversarial loss: 0.673166\n",
      "epoch 48; iter: 0; batch classifier loss: 0.243967; batch adversarial loss: 0.669857\n",
      "epoch 49; iter: 0; batch classifier loss: 0.394573; batch adversarial loss: 0.664791\n",
      "accuracy 0.788\n",
      "0.11\n",
      "1.52\n",
      "0.02\n",
      "0.01\n"
     ]
    }
   ],
   "source": [
    "# in-processing: Adversarial debiasing\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "num_epochs = 50\n",
    "classifier_num_hidden_units = 200\n",
    "model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                            unprivileged_groups = unprivileged_groups,\n",
    "                            scope_name='debiased_classifier',\n",
    "                            debias=True,\n",
    "                            sess=sess)\n",
    "model.fit(dataset_RW_train)\n",
    "prediction = model.predict(dataset_orig_test)\n",
    "get_prediction_metrics(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036a2ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:HWfairAIVenv]",
   "language": "python",
   "name": "conda-env-HWfairAIVenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
