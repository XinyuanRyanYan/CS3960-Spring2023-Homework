{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d103cdc1",
   "metadata": {},
   "source": [
    "# Homework 4: Using Learning Fair Representations to Mitigate Bias in Bank Marketing\n",
    "\n",
    "In this assignment, we will understand and use the code of a pre-processing method called **Learning Fair Representations** to mitigate bias in data. The dataset used in this homework is the same as Homework 3: Bank marketing data. \n",
    "\n",
    "You will finish the following tasks:\n",
    "\n",
    "**Please note that for each task in the homework, you are required to report both the code and results.**\n",
    "\n",
    "\n",
    "1. (10 points) Report the fairness of the dataset using two metrics, namely Disparate Impact (DI) and Statistical Parity Difference (SPD).\n",
    "\n",
    "2. (10 points) Apply Learning Fair Representations to transform the dataset. There are no specific requirements regarding the parameters.\n",
    "\n",
    "3. (10 points) Re-calculate the DI and SPD metrics on the transformed dataset and compare them with the results of the first task. What findings do you have?\n",
    "\n",
    "4. (30 points) Since LFR aims to balance two competing goals, **a** encoding the data as well as possible, and **b** obfuscating any information about protected groups. Please transform the dataset three times using LFR to emphasize goal a, emphasize goal b, and achieve a balanced trade-off between the two goals, respectively. For each transformation, also report the DI and SPD metrics on the transformed dataset.\n",
    "\n",
    "Note: \n",
    "1. To compute the fairness metrics on data, please refer to (The class BinaryLabelDatasetMetric has been imported in class):https://aif360.readthedocs.io/en/latest/modules/generated/aif360.metrics.BinaryLabelDatasetMetric.html \n",
    "\n",
    "2. More details of the usage of class LFR, please refer to https://aif360.readthedocs.io/en/latest/modules/generated/aif360.algorithms.preprocessing.LFR.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f01b3e4",
   "metadata": {},
   "source": [
    "Please carefully review the following code for LFR, to understand its functions and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e29619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize as optim\n",
    "from aif360.algorithms import Transformer\n",
    "from aif360.algorithms.preprocessing.lfr_helpers import helpers as lfr_helpers\n",
    "from aif360.datasets import BankDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    " \n",
    "class LFR(Transformer):\n",
    "    \"\"\"Learning fair representations is a pre-processing technique that finds a\n",
    "    latent representation which encodes the data well but obfuscates information\n",
    "    about protected attributes [2]_.\n",
    "    References:\n",
    "        .. [2] R. Zemel, Y. Wu, K. Swersky, T. Pitassi, and C. Dwork,  \"Learning\n",
    "           Fair Representations.\" International Conference on Machine Learning,\n",
    "           2013.\n",
    "    Based on code from https://github.com/zjelveh/learning-fair-representations\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 unprivileged_groups,\n",
    "                 privileged_groups,\n",
    "                 k=5,\n",
    "                 Ax=0.01,\n",
    "                 Ay=1.0,\n",
    "                 Az=50.0,\n",
    "                 print_interval=250,\n",
    "                 verbose=0,\n",
    "                 seed=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            unprivileged_groups (tuple): Representation for unprivileged group.\n",
    "            privileged_groups (tuple): Representation for privileged group.\n",
    "            k (int, optional): Number of prototypes.\n",
    "            Ax (float, optional): Input recontruction quality term weight.\n",
    "            Az (float, optional): Fairness constraint term weight.\n",
    "            Ay (float, optional): Output prediction error.\n",
    "            print_interval (int, optional): Print optimization objective value\n",
    "                every print_interval iterations.\n",
    "            verbose (int, optional): If zero, then no output.\n",
    "            seed (int, optional): Seed to make `predict` repeatable.\n",
    "        \"\"\"\n",
    "\n",
    "        super(LFR, self).__init__(\n",
    "            unprivileged_groups=unprivileged_groups,\n",
    "            privileged_groups=privileged_groups)\n",
    "\n",
    "        self.seed = seed\n",
    "\n",
    "        self.unprivileged_groups = unprivileged_groups\n",
    "        self.privileged_groups = privileged_groups\n",
    "        if len(self.unprivileged_groups) > 1 or len(self.privileged_groups) > 1:\n",
    "            raise ValueError(\"Only one unprivileged_group or privileged_group supported.\")\n",
    "        self.protected_attribute_name = list(self.unprivileged_groups[0].keys())[0]\n",
    "        self.unprivileged_group_protected_attribute_value = self.unprivileged_groups[0][self.protected_attribute_name]\n",
    "        self.privileged_group_protected_attribute_value = self.privileged_groups[0][self.protected_attribute_name]\n",
    "\n",
    "        self.k = k\n",
    "        self.Ax = Ax\n",
    "        self.Ay = Ay\n",
    "        self.Az = Az\n",
    "\n",
    "        self.print_interval = print_interval\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.w = None\n",
    "        self.prototypes = None\n",
    "        self.learned_model = None\n",
    "\n",
    "    def fit(self, dataset, maxiter=5000, maxfun=5000):\n",
    "        \"\"\"Compute the transformation parameters that leads to fair representations.\n",
    "        Args:\n",
    "            dataset (BinaryLabelDataset): Dataset containing true labels.\n",
    "            maxiter (int): Maximum number of iterations.\n",
    "            maxfun (int): Maxinum number of function evaluations.\n",
    "        Returns:\n",
    "            LFR: Returns self.\n",
    "        \"\"\"\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "\n",
    "        num_train_samples, self.features_dim = np.shape(dataset.features)\n",
    "\n",
    "        protected_attributes = np.reshape(\n",
    "            dataset.protected_attributes[:, dataset.protected_attribute_names.index(self.protected_attribute_name)],\n",
    "            [-1, 1])\n",
    "        unprivileged_sample_ids = np.array(np.where(protected_attributes == self.unprivileged_group_protected_attribute_value))[0].flatten()\n",
    "        privileged_sample_ids = np.array(np.where(protected_attributes == self.privileged_group_protected_attribute_value))[0].flatten()\n",
    "        features_unprivileged = dataset.features[unprivileged_sample_ids]\n",
    "        features_privileged = dataset.features[privileged_sample_ids]\n",
    "        labels_unprivileged = dataset.labels[unprivileged_sample_ids]\n",
    "        labels_privileged = dataset.labels[privileged_sample_ids]\n",
    "\n",
    "        # Initialize the LFR optim objective parameters\n",
    "        parameters_initialization = np.random.uniform(size=self.k + self.features_dim * self.k)\n",
    "        bnd = [(0, 1)]*self.k + [(None, None)]*self.features_dim*self.k\n",
    "        lfr_helpers.LFR_optim_objective.steps = 0\n",
    "\n",
    "        self.learned_model = optim.fmin_l_bfgs_b(lfr_helpers.LFR_optim_objective, x0=parameters_initialization, epsilon=1e-5,\n",
    "                                                      args=(features_unprivileged, features_privileged,\n",
    "                                        labels_unprivileged[:, 0], labels_privileged[:, 0], self.k, self.Ax,\n",
    "                                        self.Ay, self.Az, self.print_interval, self.verbose),\n",
    "                                                      bounds=bnd, approx_grad=True, maxfun=maxfun,\n",
    "                                                      maxiter=maxiter, disp=self.verbose)[0]\n",
    "        self.w = self.learned_model[:self.k]\n",
    "        self.prototypes = self.learned_model[self.k:].reshape((self.k, self.features_dim))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, dataset, threshold=0.5):\n",
    "        \"\"\"Transform the dataset using learned model parameters.\n",
    "        Args:\n",
    "            dataset (BinaryLabelDataset): Dataset containing labels that needs to be transformed.\n",
    "            threshold(float, optional): threshold parameter used for binary label prediction.\n",
    "        Returns:\n",
    "            dataset (BinaryLabelDataset): Transformed Dataset.\n",
    "        \"\"\"\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "\n",
    "        protected_attributes = np.reshape(\n",
    "            dataset.protected_attributes[:, dataset.protected_attribute_names.index(self.protected_attribute_name)],\n",
    "            [-1, 1])\n",
    "        unprivileged_sample_ids = \\\n",
    "        np.array(np.where(protected_attributes == self.unprivileged_group_protected_attribute_value))[0].flatten()\n",
    "        privileged_sample_ids = \\\n",
    "        np.array(np.where(protected_attributes == self.privileged_group_protected_attribute_value))[0].flatten()\n",
    "        features_unprivileged = dataset.features[unprivileged_sample_ids]\n",
    "        features_privileged = dataset.features[privileged_sample_ids]\n",
    "\n",
    "        _, features_hat_unprivileged, labels_hat_unprivileged = lfr_helpers.get_xhat_y_hat(self.prototypes, self.w, features_unprivileged)\n",
    "\n",
    "        _, features_hat_privileged, labels_hat_privileged = lfr_helpers.get_xhat_y_hat(self.prototypes, self.w, features_privileged)\n",
    "\n",
    "        transformed_features = np.zeros(shape=np.shape(dataset.features))\n",
    "        transformed_labels = np.zeros(shape=np.shape(dataset.labels))\n",
    "        transformed_features[unprivileged_sample_ids] = features_hat_unprivileged\n",
    "        transformed_features[privileged_sample_ids] = features_hat_privileged\n",
    "        transformed_labels[unprivileged_sample_ids] = np.reshape(labels_hat_unprivileged, [-1, 1])\n",
    "        transformed_labels[privileged_sample_ids] = np.reshape(labels_hat_privileged,[-1, 1])\n",
    "        transformed_bin_labels = (np.array(transformed_labels) > threshold).astype(np.float64)\n",
    "\n",
    "        # Mutated, fairer dataset with new labels\n",
    "        dataset_new = dataset.copy(deepcopy=True)\n",
    "        dataset_new.features = transformed_features\n",
    "        dataset_new.labels = transformed_bin_labels\n",
    "        dataset_new.scores = np.array(transformed_labels)\n",
    "\n",
    "        return dataset_new\n",
    "\n",
    "    def fit_transform(self, dataset, maxiter=5000, maxfun=5000, threshold=0.5):\n",
    "        \"\"\"Fit and transform methods sequentially.\n",
    "\n",
    "        Args:\n",
    "            dataset (BinaryLabelDataset): Dataset containing labels that needs to be transformed.\n",
    "            maxiter (int): Maximum number of iterations.\n",
    "            maxfun (int): Maxinum number of function evaluations.\n",
    "            threshold(float, optional): threshold parameter used for binary label prediction.\n",
    "        Returns:\n",
    "            dataset (BinaryLabelDataset): Transformed Dataset.\n",
    "        \"\"\"\n",
    "\n",
    "        return self.fit(dataset, maxiter=maxiter, maxfun=maxfun).transform(dataset, threshold=threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa049f39",
   "metadata": {},
   "source": [
    "The following code **[1]** loads the dataset, **[2]** sets the protected attribute as 'marital', **[3]** sets 'married' as privileged group, and **[4]** sets 'unmarried' as unprivileged group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6061fa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "protected_attribute_maps = [{1.0: 'married', 0.0: 'unmarried'}]\n",
    "dataset = BankDataset(    # load the bank data\n",
    "            protected_attribute_names=['marital'],    # set the protected attribute as 'marital'\n",
    "            privileged_classes=[['married']],    # set 'married' as privileged group,\n",
    "                                                 # 'unmarried' will be unprivileged group automatically\n",
    "            features_to_drop=['campaign', 'pdays', 'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'],\n",
    "            categorical_features=['job', 'education', 'default',\n",
    "                    'housing', 'loan', 'contact', 'month', 'day_of_week'],\n",
    "            metadata={'protected_attribute_maps': protected_attribute_maps}\n",
    "        )\n",
    "privileged_groups = [{'marital': 1}]\n",
    "unprivileged_groups = [{'marital': 0}]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1ed14d",
   "metadata": {},
   "source": [
    "Please write your code below according to above class and variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f934cb2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS3960HW",
   "language": "python",
   "name": "cs3960hw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
